{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Ensembl Python general-purpose utils","text":"<p>Centralise generic Python utils used by other projects within Ensembl design to facilitate frequent tasks such as input file path checks, archive files IO manipulation or logging setup, among others.</p>"},{"location":"#contents","title":"Contents","text":"<p>Check out installation section for further information on how to install the project.</p> <ol> <li>Install</li> <li>Usage</li> <li>Code of Conduct</li> <li>Coverage report</li> <li>Code reference</li> </ol>"},{"location":"#license","title":"License","text":"<p>Software as part of Ensembl Python general-purpose utils is distributed under the Apache-2.0 License.</p>"},{"location":"code_of_conduct/","title":"Code of Conduct","text":"<p>The Ensembl project is built on a foundation of collaboration, mutual respect and equality with a diverse and global community. We do not condone discrimination or abusive behaviour of any form. We encourage participation and engagement for everyone, in a professional manner, and wish all members of our community to adhere to the same principles.</p>"},{"location":"install/","title":"How to install this repository","text":"<p>This Python library only requires Python 3.10+ to work. However, it is likely that most modules and functionalities will be compatible with Python 3.9 as well.</p>"},{"location":"install/#basic-installation","title":"Basic installation","text":"<p>This library is publicly available in PyPI so it can be easily installed with your favourite Python dependency and packaging management tool, e.g.</p> <pre><code>pip install ensembl-utils\n</code></pre>"},{"location":"install/#development-oriented-installation","title":"Development-oriented installation","text":"<p>If you want to install this library in editable mode, we suggest you to do so via Python's virtual environment module (venv):</p> <pre><code>python -m venv &lt;VIRTUAL_ENVIRONMENT_NAME&gt;\nsource &lt;VIRTUAL_ENVIRONMENT_NAME&gt;/bin/activate\ngit clone https://github.com/Ensembl/ensembl-utils.git\ncd ensembl-utils\npip install -e .[cicd,docs]\n</code></pre> <p>Note that the documentation (<code>docs</code> tag) is generated using mkdocs. For full information visit mkdocs.org.</p>"},{"location":"usage/","title":"Using these utils","text":"<p>You can easily take advantage of the provided functionalities by importing this library in your code as usual:</p> <pre><code>import ensembl.utils\n</code></pre> <p>This library also provides some scripts that can help you via the command line: - <code>extract_file</code> - to easily extract archive files in different formats</p> <p>Note: All of them include the <code>--help</code> option to provide further information about their purpose and how to use them.</p>"},{"location":"usage/#pytest-plugin","title":"<code>pytest</code> plugin","text":"<p>This repository provides a <code>pytest</code> plugin with some useful functionalities to do unit testing. In particular, there is one fixture to access the test files in a folder with the same name as the test being run (<code>data_dir</code>) and a fixture to build and provide unit test databases (<code>test_dbs</code>).</p> <p>To use these elements you need to enable the plugin once you have installed the repository. There are two main ways to do this: 1. Explicitly indicating it when running <code>pytest</code>:     <code>bash     pytest -p ensembl.utils.plugin ...</code></p> <ol> <li>Adding the following line to your <code>conftest.py</code> file at the root of where the unit tests are located:     <code>python     pytest_plugins = (\"ensembl.utils.plugin\",)</code></li> </ol>"},{"location":"usage/#dependencies","title":"Dependencies","text":"<p>This repository has been developed to support SQLAlchemy version 1.4 (1.4.45 or later, to ensure \"future-compatibility\") as well as version 2.0+.</p>"},{"location":"reference/summary/","title":"Summary","text":"<ul> <li>ensembl<ul> <li>utils<ul> <li>archive</li> <li>argparse</li> <li>checksums</li> <li>database<ul> <li>dbconnection</li> <li>unittestdb</li> </ul> </li> <li>logging</li> <li>plugin</li> <li>rloader</li> </ul> </li> </ul> </li> </ul>"},{"location":"reference/ensembl/utils/","title":"utils","text":""},{"location":"reference/ensembl/utils/#ensembl.utils","title":"<code>ensembl.utils</code>","text":"<p>Ensembl Python general-purpose utils library.</p>"},{"location":"reference/ensembl/utils/#ensembl.utils.StrPath","title":"<code>StrPath = TypeVar('StrPath', str, os.PathLike)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/archive/","title":"archive","text":""},{"location":"reference/ensembl/utils/archive/#ensembl.utils.archive","title":"<code>ensembl.utils.archive</code>","text":"<p>Utils for common IO operations over archive files, e.g. tar or gzip.</p>"},{"location":"reference/ensembl/utils/archive/#ensembl.utils.archive.SUPPORTED_ARCHIVE_FORMATS","title":"<code>SUPPORTED_ARCHIVE_FORMATS = [ext for elem in shutil.get_unpack_formats() for ext in elem[1]]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/archive/#ensembl.utils.archive.extract_file","title":"<code>extract_file(src_file, dst_dir)</code>","text":"<p>Extracts the <code>src_file</code> into <code>dst_dir</code>.</p> <p>If the file is not an archive, it will be copied to <code>dst_dir</code>. <code>dst_dir</code> will be created if it does not exist.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>StrPath</code> <p>Path to the file to unpack.</p> required <code>dst_dir</code> <code>StrPath</code> <p>Path to the folder where to extract the file.</p> required Source code in <code>src/ensembl/utils/archive.py</code> <pre><code>def extract_file(src_file: StrPath, dst_dir: StrPath) -&gt; None:\n    \"\"\"Extracts the `src_file` into `dst_dir`.\n\n    If the file is not an archive, it will be copied to `dst_dir`. `dst_dir` will be created if it\n    does not exist.\n\n    Args:\n        src_file: Path to the file to unpack.\n        dst_dir: Path to the folder where to extract the file.\n\n    \"\"\"\n    src_file = Path(src_file)\n    extensions = {\"\".join(src_file.suffixes[i:]) for i in range(0, len(src_file.suffixes))}\n\n    if extensions.intersection(SUPPORTED_ARCHIVE_FORMATS):\n        shutil.unpack_archive(src_file, dst_dir)\n    else:\n        # Replicate the functionality of shutil.unpack_archive() by creating `dst_dir`\n        Path(dst_dir).mkdir(parents=True, exist_ok=True)\n        shutil.copy(src_file, dst_dir)\n</code></pre>"},{"location":"reference/ensembl/utils/archive/#ensembl.utils.archive.extract_file_cli","title":"<code>extract_file_cli()</code>","text":"<p>Entry-point for the <code>extract_file</code> method</p> Source code in <code>src/ensembl/utils/archive.py</code> <pre><code>def extract_file_cli() -&gt; None:\n    \"\"\"Entry-point for the `extract_file` method\"\"\"\n    parser = ArgumentParser(description=\"Extracts file to the given location.\")\n    parser.add_argument_src_path(\"--src_file\", required=True, help=\"Path to the file to unpack\")\n    parser.add_argument_dst_path(\n        \"--dst_dir\", default=Path.cwd(), help=\"Path to the folder where to extract the file\"\n    )\n    args = parser.parse_args()\n    extract_file(args.src_file, args.dst_dir)\n</code></pre>"},{"location":"reference/ensembl/utils/archive/#ensembl.utils.archive.open_gz_file","title":"<code>open_gz_file(file_path)</code>","text":"<p>Yields an open file object, even if the file is compressed with gzip.</p> <p>The file is expected to contain a text, and this can be used with the usual \"with\".</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>StrPath</code> <p>A (single) file path to open.</p> required Source code in <code>src/ensembl/utils/archive.py</code> <pre><code>@contextmanager\ndef open_gz_file(file_path: StrPath) -&gt; Generator[TextIO, None, None]:\n    \"\"\"Yields an open file object, even if the file is compressed with gzip.\n\n    The file is expected to contain a text, and this can be used with the usual \"with\".\n\n    Args:\n        file_path: A (single) file path to open.\n\n    \"\"\"\n    src_file = Path(file_path)\n    if src_file.suffix == \".gz\":\n        with gzip.open(src_file, \"rt\") as fh:\n            yield fh\n    else:\n        with src_file.open(\"rt\") as fh:\n            yield fh\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/","title":"argparse","text":""},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse","title":"<code>ensembl.utils.argparse</code>","text":"<p>Provide an extended version of <code>argparse.ArgumentParser</code> with additional functionality.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from ensembl.util.argparse import ArgumentParser\n&gt;&gt;&gt; parser = ArgumentParser(description=\"Tool description\")\n&gt;&gt;&gt; parser.add_argument_src_path(\"--src_file\", required=True, help=\"Path to source file\")\n&gt;&gt;&gt; parser.add_server_arguments(help=\"Server to connect to\")\n&gt;&gt;&gt; args = parser.parse_args()\n&gt;&gt;&gt; args\nNamespace(host='localhost', port=3826, src_file=PosixPath('/path/to/src_file.txt'),\nurl=URL('mysql://username@localhost:3826'), user='username')\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentError","title":"<code>ArgumentError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>An error from creating an argument (optional or positional).</p> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>class ArgumentError(Exception):\n    \"\"\"An error from creating an argument (optional or positional).\"\"\"\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser","title":"<code>ArgumentParser</code>","text":"<p>               Bases: <code>ArgumentParser</code></p> <p>Extends <code>argparse.ArgumentParser</code> with additional methods and functionality.</p> <p>The default behaviour of the help text will be to display the default values on every non-required argument, i.e. optional arguments with <code>required=False</code>.</p> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>class ArgumentParser(argparse.ArgumentParser):\n    \"\"\"Extends `argparse.ArgumentParser` with additional methods and functionality.\n\n    The default behaviour of the help text will be to display the default values on every non-required\n    argument, i.e. optional arguments with `required=False`.\n\n    \"\"\"\n\n    def __init__(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Extends the base class to include the information about default argument values by default.\"\"\"\n        super().__init__(*args, **kwargs)\n        self.formatter_class = argparse.ArgumentDefaultsHelpFormatter\n\n    def _validate_src_path(self, src_path: StrPath) -&gt; Path:\n        \"\"\"Returns the path if exists and it is readable, raises an error through the parser otherwise.\n\n        Args:\n            src_path: File or directory path to check.\n\n        \"\"\"\n        src_path = Path(src_path)\n        if not src_path.exists():\n            self.error(f\"'{src_path}' not found\")\n        elif not os.access(src_path, os.R_OK):\n            self.error(f\"'{src_path}' not readable\")\n        return src_path\n\n    def _validate_dst_path(self, dst_path: StrPath, exists_ok: bool = False) -&gt; Path:\n        \"\"\"Returns the path if it is writable, raises an error through the parser otherwise.\n\n        Args:\n            dst_path: File or directory path to check.\n            exists_ok: Do not raise an error during parsing if the destination path already exists.\n\n        \"\"\"\n        dst_path = Path(dst_path)\n        if dst_path.exists():\n            if os.access(dst_path, os.W_OK):\n                if exists_ok:\n                    return dst_path\n                self.error(f\"'{dst_path}' already exists\")\n            else:\n                self.error(f\"'{dst_path}' is not writable\")\n        # Check if the first parent directory that exists is writable\n        for parent_path in dst_path.parents:\n            if parent_path.exists():\n                if not os.access(parent_path, os.W_OK):\n                    self.error(f\"'{dst_path}' is not writable\")\n                break\n        return dst_path\n\n    def _validate_number(\n        self,\n        value: str,\n        value_type: Callable[[str], int | float],\n        min_value: int | float | None,\n        max_value: int | float | None,\n    ) -&gt; int | float:\n        \"\"\"Returns the numeric value if it is of the expected type and it is within the specified range.\n\n        Args:\n            value: String representation of numeric value to check.\n            value_type: Expected type of the numeric value.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # Check if the string representation can be converted to the expected type\n        try:\n            result = value_type(value)\n        except (TypeError, ValueError):\n            self.error(f\"invalid {value_type.__name__} value: {value}\")\n        # Check if numeric value is within range\n        if (min_value is not None) and (result &lt; min_value):\n            self.error(f\"{value} is lower than minimum value ({min_value})\")\n        if (max_value is not None) and (result &gt; max_value):\n            self.error(f\"{value} is greater than maximum value ({max_value})\")\n        return result\n\n    def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n        \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n        Only applied to required arguments without a default value, i.e. positional arguments or optional\n        arguments with `required=True`.\n\n        \"\"\"\n        if kwargs.get(\"required\", False):\n            kwargs.setdefault(\"default\", argparse.SUPPRESS)\n        super().add_argument(*args, **kwargs)\n\n    def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n        If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = self._validate_src_path\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n        If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n        Args:\n            exists_ok: Do not raise an error if the destination path already exists.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"PATH\")\n        kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n        self.add_argument(*args, **kwargs)\n\n    def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n        \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n        If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n        \"\"\"\n        kwargs.setdefault(\"metavar\", \"URI\")\n        kwargs[\"type\"] = make_url\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_numeric_argument(\n        self,\n        *args: Any,\n        type: Callable[[str], int | float] = float,\n        min_value: int | float | None = None,\n        max_value: int | float | None = None,\n        **kwargs: Any,\n    ) -&gt; None:\n        \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n        Note that the default value (if defined) is not checked unless the argument is an optional argument\n        and no value is provided in the command line.\n\n        Args:\n            type: Type to convert the argument value to when parsing.\n            min_value: Minimum value constrain. If `None`, no minimum value constrain.\n            max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n        \"\"\"\n        # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n        if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n            raise ArgumentError(\"minimum value is greater than maximum value\")\n        # Add lambda function to check numeric constrains when parsing argument\n        kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n        self.add_argument(*args, **kwargs)\n\n    # pylint: disable=redefined-builtin\n    def add_server_arguments(\n        self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n    ) -&gt; None:\n        \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n        and `--password` (optional).\n\n        Note that the parser will assume this is a MySQL server.\n\n        Args:\n            prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n                `--src_host`, etc.\n            include_database: Include `--database` argument.\n            help: Description message to include for this set of arguments.\n\n        \"\"\"\n        group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n        group.add_argument(\n            f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n        )\n        group.add_argument(\n            f\"--{prefix}port\",\n            required=True,\n            type=int,\n            metavar=\"PORT\",\n            default=argparse.SUPPRESS,\n            help=\"port number\",\n        )\n        group.add_argument(\n            f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n        )\n        group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n        if include_database:\n            group.add_argument(\n                f\"--{prefix}database\",\n                required=True,\n                metavar=\"NAME\",\n                default=argparse.SUPPRESS,\n                help=\"database name\",\n            )\n\n    def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n        \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n        The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n        `--debug` or `--log LEVEL`.\n\n        Args:\n            add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n                `--log_file_level`.\n\n        \"\"\"\n        # Define the list of log levels available\n        log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n        # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n        # Create logging arguments group\n        group = self.add_argument_group(\"logging arguments\")\n        # Add 3 mutually exclusive options to set the logging level\n        subgroup = group.add_mutually_exclusive_group()\n        subgroup.add_argument(\n            \"-v\",\n            \"--verbose\",\n            action=\"store_const\",\n            const=\"INFO\",\n            dest=\"log_level\",\n            help=\"verbose mode, i.e. 'INFO' log level\",\n        )\n        subgroup.add_argument(\n            \"--debug\",\n            action=\"store_const\",\n            const=\"DEBUG\",\n            dest=\"log_level\",\n            help=\"debugging mode, i.e. 'DEBUG' log level\",\n        )\n        subgroup.add_argument(\n            \"--log\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"WARNING\",\n            metavar=\"LEVEL\",\n            dest=\"log_level\",\n            help=\"level of the events to track: %(choices)s\",\n        )\n        subgroup.set_defaults(log_level=\"WARNING\")\n        if add_log_file:\n            # Add log file-related arguments\n            group.add_argument(\n                \"--log_file\",\n                type=lambda x: self._validate_dst_path(x, exists_ok=True),\n                metavar=\"PATH\",\n                default=None,\n                help=\"log file path\",\n            )\n            group.add_argument(\n                \"--log_file_level\",\n                choices=log_levels,\n                type=str.upper,\n                default=\"DEBUG\",\n                metavar=\"LEVEL\",\n                help=\"level of the events to track in the log file: %(choices)s\",\n            )\n\n    def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n        \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n        The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n        arguments for debugging purposes when logging arguments have been added.\n\n        \"\"\"\n        arguments = super().parse_args(*args, **kwargs)\n        # Build and add an sqlalchemy.engine.URL object for every server group added\n        pattern = re.compile(r\"([\\w-]*)host$\")\n        server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n        for prefix in server_prefixes:\n            # Raise an error rather than overwriting when the URL argument is already present\n            if f\"{prefix}url\" in arguments:\n                self.error(f\"argument '{prefix}url' is already present\")\n            try:\n                server_url = URL.create(\n                    \"mysql\",\n                    getattr(arguments, f\"{prefix}user\"),\n                    getattr(arguments, f\"{prefix}password\"),\n                    getattr(arguments, f\"{prefix}host\"),\n                    getattr(arguments, f\"{prefix}port\"),\n                    getattr(arguments, f\"{prefix}database\", None),\n                )\n            except AttributeError:\n                # Not a database server host argument\n                continue\n            setattr(arguments, f\"{prefix}url\", server_url)\n        return arguments\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.formatter_class","title":"<code>formatter_class = argparse.ArgumentDefaultsHelpFormatter</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.add_argument","title":"<code>add_argument(*args, **kwargs)</code>","text":"<p>Extends the parent function by excluding the default value in the help text when not provided.</p> <p>Only applied to required arguments without a default value, i.e. positional arguments or optional arguments with <code>required=True</code>.</p> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def add_argument(self, *args: Any, **kwargs: Any) -&gt; None:  # type: ignore[override]\n    \"\"\"Extends the parent function by excluding the default value in the help text when not provided.\n\n    Only applied to required arguments without a default value, i.e. positional arguments or optional\n    arguments with `required=True`.\n\n    \"\"\"\n    if kwargs.get(\"required\", False):\n        kwargs.setdefault(\"default\", argparse.SUPPRESS)\n    super().add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.add_argument_dst_path","title":"<code>add_argument_dst_path(*args, exists_ok=True, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it is writable at parsing time.</p> <p>If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.</p> <p>Parameters:</p> Name Type Description Default <code>exists_ok</code> <code>bool</code> <p>Do not raise an error if the destination path already exists.</p> <code>True</code> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def add_argument_dst_path(self, *args: Any, exists_ok: bool = True, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it is writable at parsing time.\n\n    If \"metavar\" is not defined it is added with \"PATH\" as value to improve help text readability.\n\n    Args:\n        exists_ok: Do not raise an error if the destination path already exists.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = lambda x: self._validate_dst_path(x, exists_ok)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.add_argument_src_path","title":"<code>add_argument_src_path(*args, **kwargs)</code>","text":"<p>Adds <code>pathlib.Path</code> argument, checking if it exists and it is readable at parsing time.</p> <p>If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.</p> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def add_argument_src_path(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `pathlib.Path` argument, checking if it exists and it is readable at parsing time.\n\n    If \"metavar\" is not defined, it is added with \"PATH\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"PATH\")\n    kwargs[\"type\"] = self._validate_src_path\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.add_argument_url","title":"<code>add_argument_url(*args, **kwargs)</code>","text":"<p>Adds <code>sqlalchemy.engine.URL</code> argument.</p> <p>If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.</p> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def add_argument_url(self, *args: Any, **kwargs: Any) -&gt; None:\n    \"\"\"Adds `sqlalchemy.engine.URL` argument.\n\n    If \"metavar\" is not defined it is added with \"URI\" as value to improve help text readability.\n\n    \"\"\"\n    kwargs.setdefault(\"metavar\", \"URI\")\n    kwargs[\"type\"] = make_url\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.add_log_arguments","title":"<code>add_log_arguments(add_log_file=False)</code>","text":"<p>Adds the usual set of arguments required to set and initialise a logging system.</p> <p>The current set includes a mutually exclusive group for the default logging level: <code>--verbose</code>, <code>--debug</code> or <code>--log LEVEL</code>.</p> <p>Parameters:</p> Name Type Description Default <code>add_log_file</code> <code>bool</code> <p>Add arguments to allow storing messages into a file, i.e. <code>--log_file</code> and <code>--log_file_level</code>.</p> <code>False</code> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def add_log_arguments(self, add_log_file: bool = False) -&gt; None:\n    \"\"\"Adds the usual set of arguments required to set and initialise a logging system.\n\n    The current set includes a mutually exclusive group for the default logging level: `--verbose`,\n    `--debug` or `--log LEVEL`.\n\n    Args:\n        add_log_file: Add arguments to allow storing messages into a file, i.e. `--log_file` and\n            `--log_file_level`.\n\n    \"\"\"\n    # Define the list of log levels available\n    log_levels = [\"DEBUG\", \"INFO\", \"WARNING\", \"ERROR\", \"CRITICAL\"]\n    # NOTE: from 3.11 this list can be changed to: logging.getLevelNamesMapping().keys()\n    # Create logging arguments group\n    group = self.add_argument_group(\"logging arguments\")\n    # Add 3 mutually exclusive options to set the logging level\n    subgroup = group.add_mutually_exclusive_group()\n    subgroup.add_argument(\n        \"-v\",\n        \"--verbose\",\n        action=\"store_const\",\n        const=\"INFO\",\n        dest=\"log_level\",\n        help=\"verbose mode, i.e. 'INFO' log level\",\n    )\n    subgroup.add_argument(\n        \"--debug\",\n        action=\"store_const\",\n        const=\"DEBUG\",\n        dest=\"log_level\",\n        help=\"debugging mode, i.e. 'DEBUG' log level\",\n    )\n    subgroup.add_argument(\n        \"--log\",\n        choices=log_levels,\n        type=str.upper,\n        default=\"WARNING\",\n        metavar=\"LEVEL\",\n        dest=\"log_level\",\n        help=\"level of the events to track: %(choices)s\",\n    )\n    subgroup.set_defaults(log_level=\"WARNING\")\n    if add_log_file:\n        # Add log file-related arguments\n        group.add_argument(\n            \"--log_file\",\n            type=lambda x: self._validate_dst_path(x, exists_ok=True),\n            metavar=\"PATH\",\n            default=None,\n            help=\"log file path\",\n        )\n        group.add_argument(\n            \"--log_file_level\",\n            choices=log_levels,\n            type=str.upper,\n            default=\"DEBUG\",\n            metavar=\"LEVEL\",\n            help=\"level of the events to track in the log file: %(choices)s\",\n        )\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.add_numeric_argument","title":"<code>add_numeric_argument(*args, type=float, min_value=None, max_value=None, **kwargs)</code>","text":"<p>Adds a numeric argument with constrains on its type and its minimum or maximum value.</p> <p>Note that the default value (if defined) is not checked unless the argument is an optional argument and no value is provided in the command line.</p> <p>Parameters:</p> Name Type Description Default <code>type</code> <code>Callable[[str], int | float]</code> <p>Type to convert the argument value to when parsing.</p> <code>float</code> <code>min_value</code> <code>int | float | None</code> <p>Minimum value constrain. If <code>None</code>, no minimum value constrain.</p> <code>None</code> <code>max_value</code> <code>int | float | None</code> <p>Maximum value constrain. If <code>None</code>, no maximum value constrain.</p> <code>None</code> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def add_numeric_argument(\n    self,\n    *args: Any,\n    type: Callable[[str], int | float] = float,\n    min_value: int | float | None = None,\n    max_value: int | float | None = None,\n    **kwargs: Any,\n) -&gt; None:\n    \"\"\"Adds a numeric argument with constrains on its type and its minimum or maximum value.\n\n    Note that the default value (if defined) is not checked unless the argument is an optional argument\n    and no value is provided in the command line.\n\n    Args:\n        type: Type to convert the argument value to when parsing.\n        min_value: Minimum value constrain. If `None`, no minimum value constrain.\n        max_value: Maximum value constrain. If `None`, no maximum value constrain.\n\n    \"\"\"\n    # If both minimum and maximum values are defined, ensure min_value &lt;= max_value\n    if (min_value is not None) and (max_value is not None) and (min_value &gt; max_value):\n        raise ArgumentError(\"minimum value is greater than maximum value\")\n    # Add lambda function to check numeric constrains when parsing argument\n    kwargs[\"type\"] = lambda x: self._validate_number(x, type, min_value, max_value)\n    self.add_argument(*args, **kwargs)\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.add_server_arguments","title":"<code>add_server_arguments(prefix='', include_database=False, help=None)</code>","text":"<p>Adds the usual set of arguments needed to connect to a server, i.e. <code>--host</code>, <code>--port</code>, <code>--user</code> and <code>--password</code> (optional).</p> <p>Note that the parser will assume this is a MySQL server.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix to add the each argument, e.g. if prefix is <code>src_</code>, the arguments will be <code>--src_host</code>, etc.</p> <code>''</code> <code>include_database</code> <code>bool</code> <p>Include <code>--database</code> argument.</p> <code>False</code> <code>help</code> <code>str | None</code> <p>Description message to include for this set of arguments.</p> <code>None</code> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def add_server_arguments(\n    self, prefix: str = \"\", include_database: bool = False, help: str | None = None\n) -&gt; None:\n    \"\"\"Adds the usual set of arguments needed to connect to a server, i.e. `--host`, `--port`, `--user`\n    and `--password` (optional).\n\n    Note that the parser will assume this is a MySQL server.\n\n    Args:\n        prefix: Prefix to add the each argument, e.g. if prefix is `src_`, the arguments will be\n            `--src_host`, etc.\n        include_database: Include `--database` argument.\n        help: Description message to include for this set of arguments.\n\n    \"\"\"\n    group = self.add_argument_group(f\"{prefix}server connection arguments\", description=help)\n    group.add_argument(\n        f\"--{prefix}host\", required=True, metavar=\"HOST\", default=argparse.SUPPRESS, help=\"host name\"\n    )\n    group.add_argument(\n        f\"--{prefix}port\",\n        required=True,\n        type=int,\n        metavar=\"PORT\",\n        default=argparse.SUPPRESS,\n        help=\"port number\",\n    )\n    group.add_argument(\n        f\"--{prefix}user\", required=True, metavar=\"USER\", default=argparse.SUPPRESS, help=\"user name\"\n    )\n    group.add_argument(f\"--{prefix}password\", metavar=\"PWD\", help=\"host password\")\n    if include_database:\n        group.add_argument(\n            f\"--{prefix}database\",\n            required=True,\n            metavar=\"NAME\",\n            default=argparse.SUPPRESS,\n            help=\"database name\",\n        )\n</code></pre>"},{"location":"reference/ensembl/utils/argparse/#ensembl.utils.argparse.ArgumentParser.parse_args","title":"<code>parse_args(*args, **kwargs)</code>","text":"<p>Extends the parent function by adding a new URL argument for every server group added.</p> <p>The type of this new argument will be <code>sqlalchemy.engine.URL</code>. It also logs all the parsed arguments for debugging purposes when logging arguments have been added.</p> Source code in <code>src/ensembl/utils/argparse.py</code> <pre><code>def parse_args(self, *args: Any, **kwargs: Any) -&gt; argparse.Namespace:  # type: ignore[override]\n    \"\"\"Extends the parent function by adding a new URL argument for every server group added.\n\n    The type of this new argument will be `sqlalchemy.engine.URL`. It also logs all the parsed\n    arguments for debugging purposes when logging arguments have been added.\n\n    \"\"\"\n    arguments = super().parse_args(*args, **kwargs)\n    # Build and add an sqlalchemy.engine.URL object for every server group added\n    pattern = re.compile(r\"([\\w-]*)host$\")\n    server_prefixes = [x.group(1) for x in map(pattern.match, vars(arguments)) if x]\n    for prefix in server_prefixes:\n        # Raise an error rather than overwriting when the URL argument is already present\n        if f\"{prefix}url\" in arguments:\n            self.error(f\"argument '{prefix}url' is already present\")\n        try:\n            server_url = URL.create(\n                \"mysql\",\n                getattr(arguments, f\"{prefix}user\"),\n                getattr(arguments, f\"{prefix}password\"),\n                getattr(arguments, f\"{prefix}host\"),\n                getattr(arguments, f\"{prefix}port\"),\n                getattr(arguments, f\"{prefix}database\", None),\n            )\n        except AttributeError:\n            # Not a database server host argument\n            continue\n        setattr(arguments, f\"{prefix}url\", server_url)\n    return arguments\n</code></pre>"},{"location":"reference/ensembl/utils/checksums/","title":"checksums","text":""},{"location":"reference/ensembl/utils/checksums/#ensembl.utils.checksums","title":"<code>ensembl.utils.checksums</code>","text":"<p>Utils for common hash operations (often referred to as checksums) over files, e.g. MD5 or SHA128.</p>"},{"location":"reference/ensembl/utils/checksums/#ensembl.utils.checksums.get_file_hash","title":"<code>get_file_hash(file_path, algorithm='md5')</code>","text":"<p>Returns the hash value for a given file and hash algorithm.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>StrPath</code> <p>File path to get the hash for.</p> required <code>algorithm</code> <code>str</code> <p>Secure hash or message digest algorithm name.</p> <code>'md5'</code> Source code in <code>src/ensembl/utils/checksums.py</code> <pre><code>def get_file_hash(file_path: StrPath, algorithm: str = \"md5\") -&gt; str:\n    \"\"\"Returns the hash value for a given file and hash algorithm.\n\n    Args:\n        file_path: File path to get the hash for.\n        algorithm: Secure hash or message digest algorithm name.\n    \"\"\"\n    hash_func = hashlib.new(algorithm)\n    with Path(file_path).open(\"rb\") as f:\n        data_bytes = f.read()\n    hash_func.update(data_bytes)\n    return hash_func.hexdigest()\n</code></pre>"},{"location":"reference/ensembl/utils/checksums/#ensembl.utils.checksums.validate_file_hash","title":"<code>validate_file_hash(file_path, hash_value, algorithm='md5')</code>","text":"<p>Returns true if the file's hash value is the same as the one provided for that hash algorithm, false otherwise.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>StrPath</code> <p>Path to the file to validate.</p> required <code>hash_value</code> <code>str</code> <p>Expected hash value.</p> required <code>algorithm</code> <code>str</code> <p>Secure hash or message digest algorithm name.</p> <code>'md5'</code> Source code in <code>src/ensembl/utils/checksums.py</code> <pre><code>def validate_file_hash(file_path: StrPath, hash_value: str, algorithm: str = \"md5\") -&gt; bool:\n    \"\"\"Returns true if the file's hash value is the same as the one provided for that hash\n    algorithm, false otherwise.\n\n    Args:\n        file_path: Path to the file to validate.\n        hash_value: Expected hash value.\n        algorithm: Secure hash or message digest algorithm name.\n    \"\"\"\n    file_hash = get_file_hash(file_path, algorithm)\n    return file_hash == hash_value\n</code></pre>"},{"location":"reference/ensembl/utils/logging/","title":"logging","text":""},{"location":"reference/ensembl/utils/logging/#ensembl.utils.logging","title":"<code>ensembl.utils.logging</code>","text":"<p>Easy initialisation functionality to set an event logging system.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import logging, pathlib\n&gt;&gt;&gt; from ensembl.utils.logging import init_logging\n&gt;&gt;&gt; logfile = pathlib.Path(\"test.log\")\n&gt;&gt;&gt; init_logging(\"INFO\", logfile, \"DEBUG\")\n&gt;&gt;&gt; logging.info(\"This message is written in both stderr and the log file\")\n&gt;&gt;&gt; logging.debug(\"This message is only written in the log file\")\n</code></pre>"},{"location":"reference/ensembl/utils/logging/#ensembl.utils.logging.LogLevel","title":"<code>LogLevel = Union[int, str]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/logging/#ensembl.utils.logging.formatTime","title":"<code>formatTime(record, datefmt=None)</code>","text":"<p>Returns the creation time of the log record in ISO8601 format.</p> <p>Parameters:</p> Name Type Description Default <code>record</code> <code>LogRecord</code> <p>Log record to format.</p> required <code>datefmt</code> <code>str | None</code> <p>Date format to use. Ignored in this implementation.</p> <code>None</code> Source code in <code>src/ensembl/utils/logging.py</code> <pre><code>def formatTime(\n    record: logging.LogRecord,\n    datefmt: str | None = None,  # pylint: disable=unused-argument\n) -&gt; str:\n    \"\"\"Returns the creation time of the log record in ISO8601 format.\n\n    Args:\n        record: Log record to format.\n        datefmt: Date format to use. Ignored in this implementation.\n    \"\"\"\n    return datetime.fromtimestamp(record.created).astimezone().isoformat(timespec=\"milliseconds\")\n</code></pre>"},{"location":"reference/ensembl/utils/logging/#ensembl.utils.logging.init_logging","title":"<code>init_logging(log_level='WARNING', log_file=None, log_file_level='DEBUG', msg_format='%(asctime)s [%(process)s] %(levelname)-9s %(name)-13s: %(message)s')</code>","text":"<p>Initialises the logging system.</p> <p>By default, all the log messages corresponding to <code>log_level</code> (and above) will be printed in the standard error. If <code>log_file</code> is provided, all messages of <code>log_file_level</code> level (and above) will be written into the provided file.</p> <p>Parameters:</p> Name Type Description Default <code>log_level</code> <code>LogLevel</code> <p>Minimum logging level for the standard error.</p> <code>'WARNING'</code> <code>log_file</code> <code>Optional[StrPath]</code> <p>Logging file where to write logging messages besides the standard error.</p> <code>None</code> <code>log_file_level</code> <code>LogLevel</code> <p>Minimum logging level for the logging file.</p> <code>'DEBUG'</code> <code>msg_format</code> <code>str</code> <p>A format string for the logged output as a whole. More information: https://docs.python.org/3/library/logging.html#logrecord-attributes</p> <code>'%(asctime)s [%(process)s] %(levelname)-9s %(name)-13s: %(message)s'</code> Source code in <code>src/ensembl/utils/logging.py</code> <pre><code>def init_logging(\n    log_level: LogLevel = \"WARNING\",\n    log_file: Optional[StrPath] = None,\n    log_file_level: LogLevel = \"DEBUG\",\n    msg_format: str = \"%(asctime)s [%(process)s] %(levelname)-9s %(name)-13s: %(message)s\",\n) -&gt; None:\n    \"\"\"Initialises the logging system.\n\n    By default, all the log messages corresponding to `log_level` (and above) will be printed in the\n    standard error. If `log_file` is provided, all messages of `log_file_level` level (and above) will\n    be written into the provided file.\n\n    Args:\n        log_level: Minimum logging level for the standard error.\n        log_file: Logging file where to write logging messages besides the standard error.\n        log_file_level: Minimum logging level for the logging file.\n        msg_format: A format string for the logged output as a whole. More information:\n            https://docs.python.org/3/library/logging.html#logrecord-attributes\n\n    \"\"\"\n    # Define new formatter used for handlers\n    formatter = logging.Formatter(msg_format)\n    formatter.formatTime = formatTime  # type: ignore[method-assign]\n    # Configure the basic logging system, setting the root logger to the minimum log level available\n    # to avoid filtering messages in any handler due to \"parent delegation\". Also close and remove any\n    # existing handlers before setting this configuration.\n    logging.basicConfig(level=\"DEBUG\", force=True)\n    # Set the correct log level and format of the new StreamHandler (by default the latter is set to NOTSET)\n    logging.root.handlers[0].setLevel(log_level)\n    logging.root.handlers[0].setFormatter(formatter)\n    if log_file:\n        # Create the log file handler and add it to the root logger\n        file_handler = logging.FileHandler(log_file)\n        file_handler.setLevel(log_file_level)\n        file_handler.setFormatter(formatter)\n        logging.root.addHandler(file_handler)\n</code></pre>"},{"location":"reference/ensembl/utils/logging/#ensembl.utils.logging.init_logging_with_args","title":"<code>init_logging_with_args(args)</code>","text":"<p>Processes the Namespace object provided to call <code>init_logging()</code> with the correct arguments.</p> <p>Parameters:</p> Name Type Description Default <code>args</code> <code>Namespace</code> <p>Namespace populated by an argument parser.</p> required Source code in <code>src/ensembl/utils/logging.py</code> <pre><code>def init_logging_with_args(args: argparse.Namespace) -&gt; None:\n    \"\"\"Processes the Namespace object provided to call `init_logging()` with the correct arguments.\n\n    Args:\n        args: Namespace populated by an argument parser.\n\n    \"\"\"\n    args_dict = vars(args)\n    log_args = {x: args_dict[x] for x in [\"log_level\", \"log_file\", \"log_file_level\"] if x in args_dict}\n    init_logging(**log_args)\n</code></pre>"},{"location":"reference/ensembl/utils/plugin/","title":"plugin","text":""},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin","title":"<code>ensembl.utils.plugin</code>","text":"<p>Ensembl's pytest plugin with useful unit testing hooks and fixtures.</p>"},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.DBFactory","title":"<code>DBFactory = Callable[[StrPath | None, str | None, MetaData | None], UnitTestDB]</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.fixture_assert_files","title":"<code>fixture_assert_files()</code>","text":"<p>Returns a function that asserts if two text files are equal, or prints their differences.</p> Source code in <code>src/ensembl/utils/plugin.py</code> <pre><code>@pytest.fixture(name=\"assert_files\")\ndef fixture_assert_files() -&gt; Callable[[StrPath, StrPath], None]:\n    \"\"\"Returns a function that asserts if two text files are equal, or prints their differences.\"\"\"\n\n    def _assert_files(result_path: StrPath, expected_path: StrPath) -&gt; None:\n        \"\"\"Asserts if two files are equal, or prints their differences.\n\n        Args:\n            result_path: Path to results (test-made) file.\n            expected_path: Path to expected file.\n\n        \"\"\"\n        with open(result_path, \"r\") as result_fh:\n            results = result_fh.readlines()\n        with open(expected_path, \"r\") as expected_fh:\n            expected = expected_fh.readlines()\n        files_diff = list(\n            unified_diff(\n                results,\n                expected,\n                fromfile=f\"Test-made file {Path(result_path).name}\",\n                tofile=f\"Expected file {Path(expected_path).name}\",\n            )\n        )\n        assert_message = f\"Test-made and expected files differ\\n{' '.join(files_diff)}\"\n        assert len(files_diff) == 0, assert_message\n\n    return _assert_files\n</code></pre>"},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.fixture_db_factory","title":"<code>fixture_db_factory(request, data_dir)</code>","text":"<p>Yields a unit test database factory.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>FixtureRequest</code> <p>Fixture that provides information of the requesting test function.</p> required <code>data_dir</code> <code>Path</code> <p>Fixture that provides the path to the test data folder matching the test's name.</p> required Source code in <code>src/ensembl/utils/plugin.py</code> <pre><code>@pytest.fixture(name=\"db_factory\", scope=\"module\")\ndef fixture_db_factory(request: FixtureRequest, data_dir: Path) -&gt; Generator[DBFactory, None, None]:\n    \"\"\"Yields a unit test database factory.\n\n    Args:\n        request: Fixture that provides information of the requesting test function.\n        data_dir: Fixture that provides the path to the test data folder matching the test's name.\n\n    \"\"\"\n    created: dict[str, UnitTestDB] = {}\n    server_url = request.config.getoption(\"server\")\n\n    def _db_factory(\n        src: StrPath | None, name: str | None = None, metadata: MetaData | None = None\n    ) -&gt; UnitTestDB:\n        \"\"\"Returns a unit test database.\n\n        Args:\n            src: Directory path where the test database schema and content files are located, if any.\n            name: Name to give to the new database. See `UnitTestDB` for more information.\n            metadata: SQLAlchemy ORM schema metadata to populate the schema of the test database.\n\n        \"\"\"\n        if src is not None:\n            src_path = Path(src)\n            if not src_path.is_absolute():\n                src_path = data_dir / src_path\n            db_key = name if name else src_path.name\n            dump_dir: Path | None = src_path if src_path.exists() else None\n        else:\n            db_key = name if name else \"dbkey\"\n            dump_dir = None\n        return created.setdefault(\n            db_key, UnitTestDB(server_url, dump_dir=dump_dir, name=name, metadata=metadata)\n        )\n\n    yield _db_factory\n    # Drop all unit test databases unless the user has requested to keep them\n    if not request.config.getoption(\"keep_dbs\"):\n        for test_db in created.values():\n            test_db.drop()\n</code></pre>"},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.local_data_dir","title":"<code>local_data_dir(request)</code>","text":"<p>Returns the path to the test data folder matching the test's name.</p> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>FixtureRequest</code> <p>Fixture that provides information of the requesting test function.</p> required Source code in <code>src/ensembl/utils/plugin.py</code> <pre><code>@pytest.fixture(name=\"data_dir\", scope=\"module\")\ndef local_data_dir(request: FixtureRequest) -&gt; Path:\n    \"\"\"Returns the path to the test data folder matching the test's name.\n\n    Args:\n        request: Fixture that provides information of the requesting test function.\n\n    \"\"\"\n    return Path(request.module.__file__).with_suffix(\"\")\n</code></pre>"},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.pytest_addoption","title":"<code>pytest_addoption(parser)</code>","text":"<p>Registers argparse-style options for Ensembl's unit testing.</p> <p><code>Pytest initialisation hook &lt;https://docs.pytest.org/en/latest/reference.html#_pytest.hookspec.pytest_addoption&gt;</code>_.</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>Parser</code> <p>Parser for command line arguments and ini-file values.</p> required Source code in <code>src/ensembl/utils/plugin.py</code> <pre><code>def pytest_addoption(parser: Parser) -&gt; None:\n    \"\"\"Registers argparse-style options for Ensembl's unit testing.\n\n    `Pytest initialisation hook\n    &lt;https://docs.pytest.org/en/latest/reference.html#_pytest.hookspec.pytest_addoption&gt;`_.\n\n    Args:\n        parser: Parser for command line arguments and ini-file values.\n\n    \"\"\"\n    # Add the Ensembl unitary test parameters to pytest parser\n    group = parser.getgroup(\"Ensembl unit testing\")\n    group.addoption(\n        \"--server\",\n        action=\"store\",\n        metavar=\"URL\",\n        dest=\"server\",\n        required=False,\n        default=os.getenv(\"DB_HOST\", \"sqlite:///\"),\n        help=\"Server URL where to create the test database(s)\",\n    )\n    group.addoption(\n        \"--keep-dbs\",\n        action=\"store_true\",\n        dest=\"keep_dbs\",\n        required=False,\n        help=\"Do not remove the test databases (default: False)\",\n    )\n</code></pre>"},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.pytest_configure","title":"<code>pytest_configure(config)</code>","text":"<p>Allows plugins and conftest files to perform initial configuration.</p> <p>More information: https://docs.pytest.org/en/latest/reference/reference.html#std-hook-pytest_configure</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>The pytest config object.</p> required Source code in <code>src/ensembl/utils/plugin.py</code> <pre><code>def pytest_configure(config: Config) -&gt; None:\n    \"\"\"Allows plugins and conftest files to perform initial configuration.\n\n    More information: https://docs.pytest.org/en/latest/reference/reference.html#std-hook-pytest_configure\n\n    Args:\n        config: The pytest config object.\n\n    \"\"\"\n    # Load server information\n    server_url = make_url(config.getoption(\"server\"))\n    # If password set, treat it as an environment variable that needs to be resolved\n    if server_url.password:\n        server_url = server_url.set(password=os.path.expandvars(server_url.password))\n        config.option.server = server_url.render_as_string(hide_password=False)\n</code></pre>"},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.pytest_report_header","title":"<code>pytest_report_header(config)</code>","text":"<p>Presents extra information in the report header.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>Config</code> <p>Access to configuration values, pluginmanager and plugin hooks.</p> required Source code in <code>src/ensembl/utils/plugin.py</code> <pre><code>def pytest_report_header(config: Config) -&gt; str:\n    \"\"\"Presents extra information in the report header.\n\n    Args:\n        config: Access to configuration values, pluginmanager and plugin hooks.\n\n    \"\"\"\n    # Show server information, masking the password value\n    server = config.getoption(\"server\")\n    server = re.sub(r\"(//[^/]+:).*(@)\", r\"\\1xxxxxx\\2\", server)\n    return f\"server: {server}\"\n</code></pre>"},{"location":"reference/ensembl/utils/plugin/#ensembl.utils.plugin.test_dbs","title":"<code>test_dbs(request, db_factory)</code>","text":"<p>Returns a dictionary of unit test databases with the database name as key.</p> <p>Requires a list of dictionaries, each with keys <code>src</code>, <code>name</code> and <code>metadata</code>, passed via <code>request.param</code>. At minimum either <code>src</code> or <code>name</code> needs to be provided. See <code>db_factory()</code> for details about each key's value.</p> <p>This fixture is a wrapper of <code>db_factory()</code> intended to be used via indirect parametrization, for example::</p> <pre><code>from ensembl.core.models import Base\n@pytest.mark.parametrize(\n    \"test_dbs\",\n    [\n        [\n            {\"src\": \"core_db\"},\n            {\"src\": \"core_db\", \"name\": \"human\"},\n            {\"src\": \"core_db\", \"name\": \"cat\", \"metadata\": Base.metadata},\n        ]\n    ],\n    indirect=True\n)\ndef test_method(..., test_dbs: dict[str, UnitTestDB], ...):\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>request</code> <code>FixtureRequest</code> <p>Fixture that provides information of the requesting test function.</p> required <code>db_factory</code> <code>Callable</code> <p>Fixture that provides a unit test database factory.</p> required Source code in <code>src/ensembl/utils/plugin.py</code> <pre><code>@pytest.fixture(scope=\"module\")\ndef test_dbs(request: FixtureRequest, db_factory: Callable) -&gt; dict[str, UnitTestDB]:\n    \"\"\"Returns a dictionary of unit test databases with the database name as key.\n\n    Requires a list of dictionaries, each with keys `src`, `name` and `metadata`, passed via `request.param`.\n    At minimum either `src` or `name` needs to be provided. See `db_factory()` for details about each key's\n    value.\n\n    This fixture is a wrapper of `db_factory()` intended to be used via indirect parametrization,\n    for example::\n\n        from ensembl.core.models import Base\n        @pytest.mark.parametrize(\n            \"test_dbs\",\n            [\n                [\n                    {\"src\": \"core_db\"},\n                    {\"src\": \"core_db\", \"name\": \"human\"},\n                    {\"src\": \"core_db\", \"name\": \"cat\", \"metadata\": Base.metadata},\n                ]\n            ],\n            indirect=True\n        )\n        def test_method(..., test_dbs: dict[str, UnitTestDB], ...):\n\n\n    Args:\n        request: Fixture that provides information of the requesting test function.\n        db_factory: Fixture that provides a unit test database factory.\n\n    \"\"\"\n    databases = {}\n    for argument in request.param:\n        src = argument.get(\"src\", None)\n        if src is not None:\n            src = Path(src)\n        name = argument.get(\"name\", None)\n        try:\n            key = name or src.name\n        except AttributeError as exc:\n            raise TypeError(\"Expected at least 'src' or 'name' argument defined\") from exc\n        databases[key] = db_factory(src=src, name=name, metadata=argument.get(\"metadata\"))\n    return databases\n</code></pre>"},{"location":"reference/ensembl/utils/rloader/","title":"rloader","text":""},{"location":"reference/ensembl/utils/rloader/#ensembl.utils.rloader","title":"<code>ensembl.utils.rloader</code>","text":"<p>Allow to seamlessly load / read the content of a remote file as if it was located locally.</p>"},{"location":"reference/ensembl/utils/rloader/#ensembl.utils.rloader.logger","title":"<code>logger = logging.getLogger(__name__)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/rloader/#ensembl.utils.rloader.RemoteFileLoader","title":"<code>RemoteFileLoader</code>","text":"<p>Loads remote files, allowing specific format parsing options.</p> <p>Parameters:</p> Name Type Description Default <code>parser</code> <code>Optional[str]</code> <p>Parser to use for this object. Default: <code>None</code> (no format-specific parsing done).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>available_formats</code> <code>set[str]</code> <p>File formats with ad-hoc parsers available.</p> <code>parser</code> <code>Optional[str]</code> <p>Parser selected for this object.</p> Source code in <code>src/ensembl/utils/rloader.py</code> <pre><code>class RemoteFileLoader:\n    \"\"\"Loads remote files, allowing specific format parsing options.\n\n    Args:\n        parser: Parser to use for this object. Default: `None` (no format-specific parsing done).\n\n    Attributes:\n        available_formats: File formats with ad-hoc parsers available.\n        parser: Parser selected for this object.\n\n    \"\"\"\n\n    available_formats: set[str] = {\"yaml\", \"ini\", \"env\", \"json\"}\n    parser: Optional[str] = None\n\n    def __init__(self, parser: Optional[str] = None) -&gt; None:\n        if parser in self.available_formats:\n            self.parser = parser\n\n    def __parse(self, content: str) -&gt; Any:\n        if self.parser == \"yaml\":\n            return yaml.load(content, yaml.SafeLoader)\n        if self.parser == \"ini\":\n            config = configparser.ConfigParser()\n            try:\n                config.read_string(content)\n            except configparser.MissingSectionHeaderError:\n                content = \"[DEFAULT]\\n\" + content\n                config.read_string(content)\n            return config\n        if self.parser == \"env\":\n            return dotenv.dotenv_values(stream=StringIO(content))\n        if self.parser == \"json\":\n            return json.loads(content)\n        # Only return content, no parsing\n        return content\n\n    def r_open(self, url: str) -&gt; Any:\n        \"\"\"Returns the parsed remote file from the given URL.\n\n        Args:\n            url: URL of the remote file to fetch.\n\n        Raises:\n            requests.exception.HTTPError: If loading or requesting the given URL returned an error.\n            requests.exception.Timeout: If a timeout was raised whilst requesting the given URL.\n\n        \"\"\"\n        try:\n            r = requests.get(url, timeout=120)\n            if r.status_code == 200:\n                return self.__parse(r.text)\n            raise requests.exceptions.HTTPError(response=r)\n        except requests.exceptions.HTTPError as ex:\n            logger.exception(f\"Error with request to {url}: {ex}\")\n            raise ex\n        except requests.exceptions.Timeout as ex:\n            logger.exception(f\"Request timed out {url}: {ex}\")\n            raise ex\n</code></pre>"},{"location":"reference/ensembl/utils/rloader/#ensembl.utils.rloader.RemoteFileLoader.available_formats","title":"<code>available_formats = {'yaml', 'ini', 'env', 'json'}</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/utils/rloader/#ensembl.utils.rloader.RemoteFileLoader.parser","title":"<code>parser = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/utils/rloader/#ensembl.utils.rloader.RemoteFileLoader.r_open","title":"<code>r_open(url)</code>","text":"<p>Returns the parsed remote file from the given URL.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>URL of the remote file to fetch.</p> required <p>Raises:</p> Type Description <code>HTTPError</code> <p>If loading or requesting the given URL returned an error.</p> <code>Timeout</code> <p>If a timeout was raised whilst requesting the given URL.</p> Source code in <code>src/ensembl/utils/rloader.py</code> <pre><code>def r_open(self, url: str) -&gt; Any:\n    \"\"\"Returns the parsed remote file from the given URL.\n\n    Args:\n        url: URL of the remote file to fetch.\n\n    Raises:\n        requests.exception.HTTPError: If loading or requesting the given URL returned an error.\n        requests.exception.Timeout: If a timeout was raised whilst requesting the given URL.\n\n    \"\"\"\n    try:\n        r = requests.get(url, timeout=120)\n        if r.status_code == 200:\n            return self.__parse(r.text)\n        raise requests.exceptions.HTTPError(response=r)\n    except requests.exceptions.HTTPError as ex:\n        logger.exception(f\"Error with request to {url}: {ex}\")\n        raise ex\n    except requests.exceptions.Timeout as ex:\n        logger.exception(f\"Request timed out {url}: {ex}\")\n        raise ex\n</code></pre>"},{"location":"reference/ensembl/utils/database/","title":"database","text":""},{"location":"reference/ensembl/utils/database/#ensembl.utils.database","title":"<code>ensembl.utils.database</code>","text":"<p>Database module.</p>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.Query","title":"<code>Query = TypeVar('Query', str, sqlalchemy.sql.expression.ClauseElement, sqlalchemy.sql.expression.TextClause)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.StrURL","title":"<code>StrURL = TypeVar('StrURL', str, sqlalchemy.engine.URL)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection","title":"<code>DBConnection</code>","text":"<p>Database connection handler, providing also the database's schema and properties.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>StrURL</code> <p>URL to the database, e.g. <code>mysql://user:passwd@host:port/my_db</code>.</p> required <code>reflect</code> <code>bool</code> <p>Reflect the database schema or not.</p> <code>True</code> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>class DBConnection:\n    \"\"\"Database connection handler, providing also the database's schema and properties.\n\n    Args:\n        url: URL to the database, e.g. `mysql://user:passwd@host:port/my_db`.\n        reflect: Reflect the database schema or not.\n\n    \"\"\"\n\n    def __init__(self, url: StrURL, reflect: bool = True, **kwargs: Any) -&gt; None:\n        self._engine = create_engine(url, future=True, **kwargs)\n        self._metadata: MetaData | None = None\n        if reflect:\n            self.load_metadata()\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Returns a string representation of this object.\"\"\"\n        return f\"{self.__class__.__name__}({self.url!r})\"\n\n    def load_metadata(self) -&gt; None:\n        \"\"\"Loads the metadata information of the database.\"\"\"\n        # Note: Just reflect() is not enough as it would not delete tables that no longer exist\n        self._metadata = sqlalchemy.MetaData()\n        self._metadata.reflect(bind=self._engine)\n\n    def create_all_tables(self, metadata: MetaData) -&gt; None:\n        \"\"\"Create the tables from the metadata and set the metadata.\n\n        This assumes the database is empty beforehand. If the tables already exist, they will be ignored.\n        If there are other tables, you may need to run `self.load_metadata()` to update the metadata schema.\n        \"\"\"\n        self._metadata = metadata\n        metadata.create_all(self._engine)\n\n    def create_table(self, table: Table) -&gt; None:\n        \"\"\"Create a table in the database and update the metadata. Do nothing if the table already exists.\"\"\"\n        table.create(self._engine)\n        # We need to update the metadata to register the new table\n        self.load_metadata()\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"Returns the database URL.\"\"\"\n        return self._engine.url.render_as_string(hide_password=False)\n\n    @property\n    def db_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the database name.\"\"\"\n        return self._engine.url.database\n\n    @property\n    def host(self) -&gt; Optional[str]:\n        \"\"\"Returns the database host.\"\"\"\n        return self._engine.url.host\n\n    @property\n    def port(self) -&gt; Optional[int]:\n        \"\"\"Returns the port of the database host.\"\"\"\n        return self._engine.url.port\n\n    @property\n    def dialect(self) -&gt; str:\n        \"\"\"Returns the SQLAlchemy database dialect name of the database host.\"\"\"\n        return self._engine.name\n\n    @property\n    def tables(self) -&gt; dict[str, sqlalchemy.schema.Table]:\n        \"\"\"Returns the database tables keyed to their name, or an empty dict if no metadata was loaded.\"\"\"\n        if self._metadata:\n            return self._metadata.tables\n        return {}\n\n    def get_primary_key_columns(self, table: str) -&gt; list[str]:\n        \"\"\"Returns the primary key column names for the given table.\n\n        Args:\n            table: Table name.\n\n        \"\"\"\n        return [col.name for col in self.tables[table].primary_key.columns.values()]\n\n    def get_columns(self, table: str) -&gt; list[str]:\n        \"\"\"Returns the column names for the given table.\n\n        Args:\n            table: Table name.\n\n        \"\"\"\n        return [col.name for col in self.tables[table].columns]\n\n    def connect(self) -&gt; sqlalchemy.engine.Connection:\n        \"\"\"Returns a new database connection.\"\"\"\n        return self._engine.connect()\n\n    def begin(self, *args: Any) -&gt; ContextManager[sqlalchemy.engine.Connection]:\n        \"\"\"Returns a context manager delivering a database connection with a transaction established.\"\"\"\n        return self._engine.begin(*args)\n\n    def dispose(self) -&gt; None:\n        \"\"\"Disposes of the connection pool.\"\"\"\n        self._engine.dispose()\n\n    def _enable_sqlite_savepoints(self, engine: sqlalchemy.engine.Engine) -&gt; None:\n        \"\"\"Enables SQLite SAVEPOINTS to allow session rollbacks.\"\"\"\n\n        @event.listens_for(engine, \"connect\")\n        def do_connect(\n            dbapi_connection: Any,  # SQLAlchemy is not clear about the type of this argument\n            connection_record: sqlalchemy.pool.ConnectionPoolEntry,  # pylint: disable=unused-argument\n        ) -&gt; None:\n            \"\"\"Disables emitting the BEGIN statement entirely, as well as COMMIT before any DDL.\"\"\"\n            dbapi_connection.isolation_level = None\n\n        @event.listens_for(engine, \"begin\")\n        def do_begin(conn: sqlalchemy.engine.Connection) -&gt; None:\n            \"\"\"Emits a custom own BEGIN.\"\"\"\n            conn.exec_driver_sql(\"BEGIN\")\n\n    @contextmanager\n    def session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n        \"\"\"Provides a transactional scope around a series of operations with rollback in case of failure.\n\n        Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n        the modifications performed to the database will persist.\n\n        \"\"\"\n        # Create a dedicated engine for this session\n        engine = create_engine(self._engine.url)\n        if self.dialect == \"sqlite\":\n            self._enable_sqlite_savepoints(engine)\n        Session = sessionmaker(future=True)\n        session = Session(bind=engine, autoflush=False)\n        try:\n            yield session\n            session.commit()\n        except:\n            # Rollback to ensure no changes are made to the database\n            session.rollback()\n            raise\n        finally:\n            # Whatever happens, make sure the session is closed\n            session.close()\n\n    @contextmanager\n    def test_session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n        \"\"\"Provides a transactional scope around a series of operations that will be rolled back at the end.\n\n        Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n        the modifications performed to the database will persist.\n\n        \"\"\"\n        # Create a dedicated engine for this session\n        engine = create_engine(self._engine.url)\n        if self.dialect == \"sqlite\":\n            self._enable_sqlite_savepoints(engine)\n        # Connect to the database\n        connection = engine.connect()\n        # Begin a non-ORM transaction\n        transaction = connection.begin()\n        # Bind an individual session to the connection\n        Session = sessionmaker(future=True)\n        try:\n            # Running on SQLAlchemy 2.0+\n            session = Session(bind=connection, join_transaction_mode=\"create_savepoint\")\n        except TypeError:\n            # Running on SQLAlchemy 1.4\n            session = Session(bind=connection)\n            # If the database supports SAVEPOINT, starting a savepoint will allow to also use rollback\n            connection.begin_nested()\n\n            # Define a new transaction event\n            @event.listens_for(session, \"after_transaction_end\")\n            def end_savepoint(\n                session: sqlalchemy.orm.Session,  # pylint: disable=unused-argument\n                transaction: sqlalchemy.orm.SessionTransaction,  # pylint: disable=unused-argument\n            ) -&gt; None:\n                if not connection.in_nested_transaction():\n                    connection.begin_nested()\n\n        try:\n            yield session\n        finally:\n            # Whatever happens, make sure the session and connection are closed, rolling back\n            # everything done with the session (including calls to commit())\n            session.close()\n            transaction.rollback()\n            connection.close()\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.db_name","title":"<code>db_name</code>  <code>property</code>","text":"<p>Returns the database name.</p>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.dialect","title":"<code>dialect</code>  <code>property</code>","text":"<p>Returns the SQLAlchemy database dialect name of the database host.</p>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.host","title":"<code>host</code>  <code>property</code>","text":"<p>Returns the database host.</p>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.port","title":"<code>port</code>  <code>property</code>","text":"<p>Returns the port of the database host.</p>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.tables","title":"<code>tables</code>  <code>property</code>","text":"<p>Returns the database tables keyed to their name, or an empty dict if no metadata was loaded.</p>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.url","title":"<code>url</code>  <code>property</code>","text":"<p>Returns the database URL.</p>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.begin","title":"<code>begin(*args)</code>","text":"<p>Returns a context manager delivering a database connection with a transaction established.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def begin(self, *args: Any) -&gt; ContextManager[sqlalchemy.engine.Connection]:\n    \"\"\"Returns a context manager delivering a database connection with a transaction established.\"\"\"\n    return self._engine.begin(*args)\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.connect","title":"<code>connect()</code>","text":"<p>Returns a new database connection.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def connect(self) -&gt; sqlalchemy.engine.Connection:\n    \"\"\"Returns a new database connection.\"\"\"\n    return self._engine.connect()\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.create_all_tables","title":"<code>create_all_tables(metadata)</code>","text":"<p>Create the tables from the metadata and set the metadata.</p> <p>This assumes the database is empty beforehand. If the tables already exist, they will be ignored. If there are other tables, you may need to run <code>self.load_metadata()</code> to update the metadata schema.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def create_all_tables(self, metadata: MetaData) -&gt; None:\n    \"\"\"Create the tables from the metadata and set the metadata.\n\n    This assumes the database is empty beforehand. If the tables already exist, they will be ignored.\n    If there are other tables, you may need to run `self.load_metadata()` to update the metadata schema.\n    \"\"\"\n    self._metadata = metadata\n    metadata.create_all(self._engine)\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.create_table","title":"<code>create_table(table)</code>","text":"<p>Create a table in the database and update the metadata. Do nothing if the table already exists.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def create_table(self, table: Table) -&gt; None:\n    \"\"\"Create a table in the database and update the metadata. Do nothing if the table already exists.\"\"\"\n    table.create(self._engine)\n    # We need to update the metadata to register the new table\n    self.load_metadata()\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.dispose","title":"<code>dispose()</code>","text":"<p>Disposes of the connection pool.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def dispose(self) -&gt; None:\n    \"\"\"Disposes of the connection pool.\"\"\"\n    self._engine.dispose()\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.get_columns","title":"<code>get_columns(table)</code>","text":"<p>Returns the column names for the given table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name.</p> required Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def get_columns(self, table: str) -&gt; list[str]:\n    \"\"\"Returns the column names for the given table.\n\n    Args:\n        table: Table name.\n\n    \"\"\"\n    return [col.name for col in self.tables[table].columns]\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.get_primary_key_columns","title":"<code>get_primary_key_columns(table)</code>","text":"<p>Returns the primary key column names for the given table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name.</p> required Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def get_primary_key_columns(self, table: str) -&gt; list[str]:\n    \"\"\"Returns the primary key column names for the given table.\n\n    Args:\n        table: Table name.\n\n    \"\"\"\n    return [col.name for col in self.tables[table].primary_key.columns.values()]\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.load_metadata","title":"<code>load_metadata()</code>","text":"<p>Loads the metadata information of the database.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def load_metadata(self) -&gt; None:\n    \"\"\"Loads the metadata information of the database.\"\"\"\n    # Note: Just reflect() is not enough as it would not delete tables that no longer exist\n    self._metadata = sqlalchemy.MetaData()\n    self._metadata.reflect(bind=self._engine)\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.session_scope","title":"<code>session_scope()</code>","text":"<p>Provides a transactional scope around a series of operations with rollback in case of failure.</p> <p>Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all the modifications performed to the database will persist.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>@contextmanager\ndef session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n    \"\"\"Provides a transactional scope around a series of operations with rollback in case of failure.\n\n    Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n    the modifications performed to the database will persist.\n\n    \"\"\"\n    # Create a dedicated engine for this session\n    engine = create_engine(self._engine.url)\n    if self.dialect == \"sqlite\":\n        self._enable_sqlite_savepoints(engine)\n    Session = sessionmaker(future=True)\n    session = Session(bind=engine, autoflush=False)\n    try:\n        yield session\n        session.commit()\n    except:\n        # Rollback to ensure no changes are made to the database\n        session.rollback()\n        raise\n    finally:\n        # Whatever happens, make sure the session is closed\n        session.close()\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.DBConnection.test_session_scope","title":"<code>test_session_scope()</code>","text":"<p>Provides a transactional scope around a series of operations that will be rolled back at the end.</p> <p>Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all the modifications performed to the database will persist.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>@contextmanager\ndef test_session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n    \"\"\"Provides a transactional scope around a series of operations that will be rolled back at the end.\n\n    Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n    the modifications performed to the database will persist.\n\n    \"\"\"\n    # Create a dedicated engine for this session\n    engine = create_engine(self._engine.url)\n    if self.dialect == \"sqlite\":\n        self._enable_sqlite_savepoints(engine)\n    # Connect to the database\n    connection = engine.connect()\n    # Begin a non-ORM transaction\n    transaction = connection.begin()\n    # Bind an individual session to the connection\n    Session = sessionmaker(future=True)\n    try:\n        # Running on SQLAlchemy 2.0+\n        session = Session(bind=connection, join_transaction_mode=\"create_savepoint\")\n    except TypeError:\n        # Running on SQLAlchemy 1.4\n        session = Session(bind=connection)\n        # If the database supports SAVEPOINT, starting a savepoint will allow to also use rollback\n        connection.begin_nested()\n\n        # Define a new transaction event\n        @event.listens_for(session, \"after_transaction_end\")\n        def end_savepoint(\n            session: sqlalchemy.orm.Session,  # pylint: disable=unused-argument\n            transaction: sqlalchemy.orm.SessionTransaction,  # pylint: disable=unused-argument\n        ) -&gt; None:\n            if not connection.in_nested_transaction():\n                connection.begin_nested()\n\n    try:\n        yield session\n    finally:\n        # Whatever happens, make sure the session and connection are closed, rolling back\n        # everything done with the session (including calls to commit())\n        session.close()\n        transaction.rollback()\n        connection.close()\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.UnitTestDB","title":"<code>UnitTestDB</code>","text":"<p>Creates and connects to a new test database, applying the schema and importing the data.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>StrURL</code> <p>URL of the server hosting the database.</p> required <code>metadata</code> <code>MetaData | None</code> <p>Use this metadata to create the schema instead of using an SQL schema file.</p> <code>None</code> <code>dump_dir</code> <code>StrPath | None</code> <p>Directory path with the database schema in <code>table.sql</code> (mandatory) and one TSV data file (without headers) per table following the convention <code>&lt;table_name&gt;.txt</code> (optional).</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name to give to the new database. If not provided, the last directory name of <code>dump_dir</code> will be used instead. In either case, the new database name will be prefixed by the username.</p> <code>None</code> <code>tmp_path</code> <code>StrPath | None</code> <p>Temp dir where the test db is created if using SQLite (otherwise use current dir).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>dbc</code> <p>Database connection handler.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>table.sql</code> is not found.</p> Source code in <code>src/ensembl/utils/database/unittestdb.py</code> <pre><code>class UnitTestDB:\n    \"\"\"Creates and connects to a new test database, applying the schema and importing the data.\n\n    Args:\n        server_url: URL of the server hosting the database.\n        metadata: Use this metadata to create the schema instead of using an SQL schema file.\n        dump_dir: Directory path with the database schema in `table.sql` (mandatory) and one TSV data\n            file (without headers) per table following the convention `&lt;table_name&gt;.txt` (optional).\n        name: Name to give to the new database. If not provided, the last directory name of `dump_dir`\n            will be used instead. In either case, the new database name will be prefixed by the username.\n        tmp_path: Temp dir where the test db is created if using SQLite (otherwise use current dir).\n\n    Attributes:\n        dbc: Database connection handler.\n\n    Raises:\n        FileNotFoundError: If `table.sql` is not found.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        server_url: StrURL,\n        *,\n        dump_dir: StrPath | None = None,\n        name: str | None = None,\n        metadata: MetaData | None = None,\n        tmp_path: StrPath | None = None,\n    ) -&gt; None:\n        db_url = make_url(server_url)\n        if not name:\n            name = Path(dump_dir).name if dump_dir else \"testdb\"\n        db_name = f\"{TEST_USERNAME}_{name}\"\n\n        # Add the database name to the URL\n        if db_url.get_dialect().name == \"sqlite\":\n            db_path = Path(tmp_path) / db_name if tmp_path else db_name\n            db_url = db_url.set(database=f\"{db_path}.db\")\n        else:\n            db_url = db_url.set(database=db_name)\n        # Enable \"local_infile\" variable for MySQL databases to allow importing data from files\n        connect_args = {}\n        if db_url.get_dialect().name == \"mysql\":\n            connect_args[\"local_infile\"] = 1\n        # Create the database, dropping it beforehand if it already exists\n        if database_exists(db_url):\n            drop_database(db_url)\n        create_database(db_url)\n        # Establish the connection to the database, load the schema and import the data\n        try:\n            self.dbc = DBConnection(db_url, connect_args=connect_args, reflect=False)\n            self._load_schema_and_data(dump_dir, metadata)\n        except:\n            # Make sure the database is deleted before raising the exception\n            drop_database(db_url)\n            raise\n        # Update the loaded metadata information of the database\n        self.dbc.load_metadata()\n\n    def _load_schema_and_data(\n        self, dump_dir: StrPath | None = None, metadata: MetaData | None = None\n    ) -&gt; None:\n        with self.dbc.begin() as conn:\n            # Set InnoDB engine as default and disable foreign key checks for MySQL databases\n            if self.dbc.dialect == \"mysql\":\n                conn.execute(text(\"SET default_storage_engine=InnoDB\"))\n                conn.execute(text(\"SET FOREIGN_KEY_CHECKS=0\"))\n\n            # Load the schema\n            if metadata:\n                metadata.create_all(conn)\n            elif dump_dir:\n                with Path(dump_dir, \"table.sql\").open(\"r\") as schema:\n                    for query in \"\".join(schema.readlines()).split(\";\"):\n                        if query.strip():\n                            conn.execute(text(query))\n\n            # And import any available data for each table\n            if dump_dir:\n                for tsv_file in Path(dump_dir).glob(\"*.txt\"):\n                    table = tsv_file.stem\n                    self._load_data(conn, table, tsv_file)\n\n            # Re-enable foreign key checks for MySQL databases\n            if self.dbc.dialect == \"mysql\":\n                conn.execute(text(\"SET FOREIGN_KEY_CHECKS=1\"))\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Returns a string representation of this object.\"\"\"\n        return f\"{self.__class__.__name__}({self.dbc.url!r})\"\n\n    def drop(self) -&gt; None:\n        \"\"\"Drops the database.\"\"\"\n        drop_database(self.dbc.url)\n        # Ensure the connection pool is properly closed and disposed\n        self.dbc.dispose()\n\n    def _load_data(self, conn: sqlalchemy.engine.Connection, table: str, src: StrPath) -&gt; None:\n        \"\"\"Loads the table data from the given file.\n\n        Args:\n            conn: Open connection to the database.\n            table: Table name to load the data to.\n            src: File path with the data in TSV format (without headers).\n\n        \"\"\"\n        if self.dbc.dialect == \"sqlite\":\n            # SQLite does not have an equivalent to \"LOAD DATA\": use its \".import\" command instead\n            subprocess.run([\"sqlite3\", self.dbc.db_name, \".mode tabs\", f\".import {src} {table}\"], check=True)\n        elif self.dbc.dialect == \"postgresql\":\n            conn.execute(text(f\"COPY {table} FROM '{src}'\"))\n        elif self.dbc.dialect == \"sqlserver\":\n            conn.execute(text(f\"BULK INSERT {table} FROM '{src}'\"))\n        else:\n            conn.execute(text(f\"LOAD DATA LOCAL INFILE '{src}' INTO TABLE {table}\"))\n\n    def __enter__(self) -&gt; UnitTestDB:\n        return self\n\n    def __exit__(self, *args: Any) -&gt; None:\n        self.drop()\n</code></pre>"},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.UnitTestDB.dbc","title":"<code>dbc = DBConnection(db_url, connect_args=connect_args, reflect=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/utils/database/#ensembl.utils.database.UnitTestDB.drop","title":"<code>drop()</code>","text":"<p>Drops the database.</p> Source code in <code>src/ensembl/utils/database/unittestdb.py</code> <pre><code>def drop(self) -&gt; None:\n    \"\"\"Drops the database.\"\"\"\n    drop_database(self.dbc.url)\n    # Ensure the connection pool is properly closed and disposed\n    self.dbc.dispose()\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/","title":"dbconnection","text":""},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection","title":"<code>ensembl.utils.database.dbconnection</code>","text":"<p>Database connection handler.</p> <p>This module provides the main class to connect to and access databases. It will be an ORM-less connection, that is, the data can only be accessed via SQL queries (see example below).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from ensembl.utils.database import DBConnection\n&gt;&gt;&gt; dbc = DBConnection(\"mysql://ensro@mysql-server:4242/mydb\")\n&gt;&gt;&gt; # You can access the database data via sql queries, for instance:\n&gt;&gt;&gt; results = dbc.execute(\"SELECT * FROM my_table;\")\n&gt;&gt;&gt; # Or via a connection in a transaction manner:\n&gt;&gt;&gt; with dbc.begin() as conn:\n&gt;&gt;&gt;     results = conn.execute(\"SELECT * FROM my_table;\")\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.Query","title":"<code>Query = TypeVar('Query', str, sqlalchemy.sql.expression.ClauseElement, sqlalchemy.sql.expression.TextClause)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.StrURL","title":"<code>StrURL = TypeVar('StrURL', str, sqlalchemy.engine.URL)</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection","title":"<code>DBConnection</code>","text":"<p>Database connection handler, providing also the database's schema and properties.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>StrURL</code> <p>URL to the database, e.g. <code>mysql://user:passwd@host:port/my_db</code>.</p> required <code>reflect</code> <code>bool</code> <p>Reflect the database schema or not.</p> <code>True</code> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>class DBConnection:\n    \"\"\"Database connection handler, providing also the database's schema and properties.\n\n    Args:\n        url: URL to the database, e.g. `mysql://user:passwd@host:port/my_db`.\n        reflect: Reflect the database schema or not.\n\n    \"\"\"\n\n    def __init__(self, url: StrURL, reflect: bool = True, **kwargs: Any) -&gt; None:\n        self._engine = create_engine(url, future=True, **kwargs)\n        self._metadata: MetaData | None = None\n        if reflect:\n            self.load_metadata()\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Returns a string representation of this object.\"\"\"\n        return f\"{self.__class__.__name__}({self.url!r})\"\n\n    def load_metadata(self) -&gt; None:\n        \"\"\"Loads the metadata information of the database.\"\"\"\n        # Note: Just reflect() is not enough as it would not delete tables that no longer exist\n        self._metadata = sqlalchemy.MetaData()\n        self._metadata.reflect(bind=self._engine)\n\n    def create_all_tables(self, metadata: MetaData) -&gt; None:\n        \"\"\"Create the tables from the metadata and set the metadata.\n\n        This assumes the database is empty beforehand. If the tables already exist, they will be ignored.\n        If there are other tables, you may need to run `self.load_metadata()` to update the metadata schema.\n        \"\"\"\n        self._metadata = metadata\n        metadata.create_all(self._engine)\n\n    def create_table(self, table: Table) -&gt; None:\n        \"\"\"Create a table in the database and update the metadata. Do nothing if the table already exists.\"\"\"\n        table.create(self._engine)\n        # We need to update the metadata to register the new table\n        self.load_metadata()\n\n    @property\n    def url(self) -&gt; str:\n        \"\"\"Returns the database URL.\"\"\"\n        return self._engine.url.render_as_string(hide_password=False)\n\n    @property\n    def db_name(self) -&gt; Optional[str]:\n        \"\"\"Returns the database name.\"\"\"\n        return self._engine.url.database\n\n    @property\n    def host(self) -&gt; Optional[str]:\n        \"\"\"Returns the database host.\"\"\"\n        return self._engine.url.host\n\n    @property\n    def port(self) -&gt; Optional[int]:\n        \"\"\"Returns the port of the database host.\"\"\"\n        return self._engine.url.port\n\n    @property\n    def dialect(self) -&gt; str:\n        \"\"\"Returns the SQLAlchemy database dialect name of the database host.\"\"\"\n        return self._engine.name\n\n    @property\n    def tables(self) -&gt; dict[str, sqlalchemy.schema.Table]:\n        \"\"\"Returns the database tables keyed to their name, or an empty dict if no metadata was loaded.\"\"\"\n        if self._metadata:\n            return self._metadata.tables\n        return {}\n\n    def get_primary_key_columns(self, table: str) -&gt; list[str]:\n        \"\"\"Returns the primary key column names for the given table.\n\n        Args:\n            table: Table name.\n\n        \"\"\"\n        return [col.name for col in self.tables[table].primary_key.columns.values()]\n\n    def get_columns(self, table: str) -&gt; list[str]:\n        \"\"\"Returns the column names for the given table.\n\n        Args:\n            table: Table name.\n\n        \"\"\"\n        return [col.name for col in self.tables[table].columns]\n\n    def connect(self) -&gt; sqlalchemy.engine.Connection:\n        \"\"\"Returns a new database connection.\"\"\"\n        return self._engine.connect()\n\n    def begin(self, *args: Any) -&gt; ContextManager[sqlalchemy.engine.Connection]:\n        \"\"\"Returns a context manager delivering a database connection with a transaction established.\"\"\"\n        return self._engine.begin(*args)\n\n    def dispose(self) -&gt; None:\n        \"\"\"Disposes of the connection pool.\"\"\"\n        self._engine.dispose()\n\n    def _enable_sqlite_savepoints(self, engine: sqlalchemy.engine.Engine) -&gt; None:\n        \"\"\"Enables SQLite SAVEPOINTS to allow session rollbacks.\"\"\"\n\n        @event.listens_for(engine, \"connect\")\n        def do_connect(\n            dbapi_connection: Any,  # SQLAlchemy is not clear about the type of this argument\n            connection_record: sqlalchemy.pool.ConnectionPoolEntry,  # pylint: disable=unused-argument\n        ) -&gt; None:\n            \"\"\"Disables emitting the BEGIN statement entirely, as well as COMMIT before any DDL.\"\"\"\n            dbapi_connection.isolation_level = None\n\n        @event.listens_for(engine, \"begin\")\n        def do_begin(conn: sqlalchemy.engine.Connection) -&gt; None:\n            \"\"\"Emits a custom own BEGIN.\"\"\"\n            conn.exec_driver_sql(\"BEGIN\")\n\n    @contextmanager\n    def session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n        \"\"\"Provides a transactional scope around a series of operations with rollback in case of failure.\n\n        Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n        the modifications performed to the database will persist.\n\n        \"\"\"\n        # Create a dedicated engine for this session\n        engine = create_engine(self._engine.url)\n        if self.dialect == \"sqlite\":\n            self._enable_sqlite_savepoints(engine)\n        Session = sessionmaker(future=True)\n        session = Session(bind=engine, autoflush=False)\n        try:\n            yield session\n            session.commit()\n        except:\n            # Rollback to ensure no changes are made to the database\n            session.rollback()\n            raise\n        finally:\n            # Whatever happens, make sure the session is closed\n            session.close()\n\n    @contextmanager\n    def test_session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n        \"\"\"Provides a transactional scope around a series of operations that will be rolled back at the end.\n\n        Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n        the modifications performed to the database will persist.\n\n        \"\"\"\n        # Create a dedicated engine for this session\n        engine = create_engine(self._engine.url)\n        if self.dialect == \"sqlite\":\n            self._enable_sqlite_savepoints(engine)\n        # Connect to the database\n        connection = engine.connect()\n        # Begin a non-ORM transaction\n        transaction = connection.begin()\n        # Bind an individual session to the connection\n        Session = sessionmaker(future=True)\n        try:\n            # Running on SQLAlchemy 2.0+\n            session = Session(bind=connection, join_transaction_mode=\"create_savepoint\")\n        except TypeError:\n            # Running on SQLAlchemy 1.4\n            session = Session(bind=connection)\n            # If the database supports SAVEPOINT, starting a savepoint will allow to also use rollback\n            connection.begin_nested()\n\n            # Define a new transaction event\n            @event.listens_for(session, \"after_transaction_end\")\n            def end_savepoint(\n                session: sqlalchemy.orm.Session,  # pylint: disable=unused-argument\n                transaction: sqlalchemy.orm.SessionTransaction,  # pylint: disable=unused-argument\n            ) -&gt; None:\n                if not connection.in_nested_transaction():\n                    connection.begin_nested()\n\n        try:\n            yield session\n        finally:\n            # Whatever happens, make sure the session and connection are closed, rolling back\n            # everything done with the session (including calls to commit())\n            session.close()\n            transaction.rollback()\n            connection.close()\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.db_name","title":"<code>db_name</code>  <code>property</code>","text":"<p>Returns the database name.</p>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.dialect","title":"<code>dialect</code>  <code>property</code>","text":"<p>Returns the SQLAlchemy database dialect name of the database host.</p>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.host","title":"<code>host</code>  <code>property</code>","text":"<p>Returns the database host.</p>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.port","title":"<code>port</code>  <code>property</code>","text":"<p>Returns the port of the database host.</p>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.tables","title":"<code>tables</code>  <code>property</code>","text":"<p>Returns the database tables keyed to their name, or an empty dict if no metadata was loaded.</p>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.url","title":"<code>url</code>  <code>property</code>","text":"<p>Returns the database URL.</p>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.begin","title":"<code>begin(*args)</code>","text":"<p>Returns a context manager delivering a database connection with a transaction established.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def begin(self, *args: Any) -&gt; ContextManager[sqlalchemy.engine.Connection]:\n    \"\"\"Returns a context manager delivering a database connection with a transaction established.\"\"\"\n    return self._engine.begin(*args)\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.connect","title":"<code>connect()</code>","text":"<p>Returns a new database connection.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def connect(self) -&gt; sqlalchemy.engine.Connection:\n    \"\"\"Returns a new database connection.\"\"\"\n    return self._engine.connect()\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.create_all_tables","title":"<code>create_all_tables(metadata)</code>","text":"<p>Create the tables from the metadata and set the metadata.</p> <p>This assumes the database is empty beforehand. If the tables already exist, they will be ignored. If there are other tables, you may need to run <code>self.load_metadata()</code> to update the metadata schema.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def create_all_tables(self, metadata: MetaData) -&gt; None:\n    \"\"\"Create the tables from the metadata and set the metadata.\n\n    This assumes the database is empty beforehand. If the tables already exist, they will be ignored.\n    If there are other tables, you may need to run `self.load_metadata()` to update the metadata schema.\n    \"\"\"\n    self._metadata = metadata\n    metadata.create_all(self._engine)\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.create_table","title":"<code>create_table(table)</code>","text":"<p>Create a table in the database and update the metadata. Do nothing if the table already exists.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def create_table(self, table: Table) -&gt; None:\n    \"\"\"Create a table in the database and update the metadata. Do nothing if the table already exists.\"\"\"\n    table.create(self._engine)\n    # We need to update the metadata to register the new table\n    self.load_metadata()\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.dispose","title":"<code>dispose()</code>","text":"<p>Disposes of the connection pool.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def dispose(self) -&gt; None:\n    \"\"\"Disposes of the connection pool.\"\"\"\n    self._engine.dispose()\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.get_columns","title":"<code>get_columns(table)</code>","text":"<p>Returns the column names for the given table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name.</p> required Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def get_columns(self, table: str) -&gt; list[str]:\n    \"\"\"Returns the column names for the given table.\n\n    Args:\n        table: Table name.\n\n    \"\"\"\n    return [col.name for col in self.tables[table].columns]\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.get_primary_key_columns","title":"<code>get_primary_key_columns(table)</code>","text":"<p>Returns the primary key column names for the given table.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>Table name.</p> required Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def get_primary_key_columns(self, table: str) -&gt; list[str]:\n    \"\"\"Returns the primary key column names for the given table.\n\n    Args:\n        table: Table name.\n\n    \"\"\"\n    return [col.name for col in self.tables[table].primary_key.columns.values()]\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.load_metadata","title":"<code>load_metadata()</code>","text":"<p>Loads the metadata information of the database.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>def load_metadata(self) -&gt; None:\n    \"\"\"Loads the metadata information of the database.\"\"\"\n    # Note: Just reflect() is not enough as it would not delete tables that no longer exist\n    self._metadata = sqlalchemy.MetaData()\n    self._metadata.reflect(bind=self._engine)\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.session_scope","title":"<code>session_scope()</code>","text":"<p>Provides a transactional scope around a series of operations with rollback in case of failure.</p> <p>Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all the modifications performed to the database will persist.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>@contextmanager\ndef session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n    \"\"\"Provides a transactional scope around a series of operations with rollback in case of failure.\n\n    Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n    the modifications performed to the database will persist.\n\n    \"\"\"\n    # Create a dedicated engine for this session\n    engine = create_engine(self._engine.url)\n    if self.dialect == \"sqlite\":\n        self._enable_sqlite_savepoints(engine)\n    Session = sessionmaker(future=True)\n    session = Session(bind=engine, autoflush=False)\n    try:\n        yield session\n        session.commit()\n    except:\n        # Rollback to ensure no changes are made to the database\n        session.rollback()\n        raise\n    finally:\n        # Whatever happens, make sure the session is closed\n        session.close()\n</code></pre>"},{"location":"reference/ensembl/utils/database/dbconnection/#ensembl.utils.database.dbconnection.DBConnection.test_session_scope","title":"<code>test_session_scope()</code>","text":"<p>Provides a transactional scope around a series of operations that will be rolled back at the end.</p> <p>Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all the modifications performed to the database will persist.</p> Source code in <code>src/ensembl/utils/database/dbconnection.py</code> <pre><code>@contextmanager\ndef test_session_scope(self) -&gt; Generator[sqlalchemy.orm.Session, None, None]:\n    \"\"\"Provides a transactional scope around a series of operations that will be rolled back at the end.\n\n    Bear in mind MySQL's storage engine MyISAM does not support rollback transactions, so all\n    the modifications performed to the database will persist.\n\n    \"\"\"\n    # Create a dedicated engine for this session\n    engine = create_engine(self._engine.url)\n    if self.dialect == \"sqlite\":\n        self._enable_sqlite_savepoints(engine)\n    # Connect to the database\n    connection = engine.connect()\n    # Begin a non-ORM transaction\n    transaction = connection.begin()\n    # Bind an individual session to the connection\n    Session = sessionmaker(future=True)\n    try:\n        # Running on SQLAlchemy 2.0+\n        session = Session(bind=connection, join_transaction_mode=\"create_savepoint\")\n    except TypeError:\n        # Running on SQLAlchemy 1.4\n        session = Session(bind=connection)\n        # If the database supports SAVEPOINT, starting a savepoint will allow to also use rollback\n        connection.begin_nested()\n\n        # Define a new transaction event\n        @event.listens_for(session, \"after_transaction_end\")\n        def end_savepoint(\n            session: sqlalchemy.orm.Session,  # pylint: disable=unused-argument\n            transaction: sqlalchemy.orm.SessionTransaction,  # pylint: disable=unused-argument\n        ) -&gt; None:\n            if not connection.in_nested_transaction():\n                connection.begin_nested()\n\n    try:\n        yield session\n    finally:\n        # Whatever happens, make sure the session and connection are closed, rolling back\n        # everything done with the session (including calls to commit())\n        session.close()\n        transaction.rollback()\n        connection.close()\n</code></pre>"},{"location":"reference/ensembl/utils/database/unittestdb/","title":"unittestdb","text":""},{"location":"reference/ensembl/utils/database/unittestdb/#ensembl.utils.database.unittestdb","title":"<code>ensembl.utils.database.unittestdb</code>","text":"<p>Unit testing database handler.</p> <p>This module provides the main class to create and drop testing databases, populating them from preexisting dumps (if supplied).</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from ensembl.utils.database import UnitTestDB\n&gt;&gt;&gt; # For more safety use the context manager (automatically drops the database even if things go wrong):\n&gt;&gt;&gt; with UnitTestDB(\"mysql://user:passwd@mysql-server:4242/\", \"path/to/dumps\", \"my_db\") as test_db:\n&gt;&gt;&gt;    dbc = test_db.dbc\n\n&gt;&gt;&gt; # If you know what you are doing you can also control when the test_db is dropped:\n&gt;&gt;&gt; test_db = UnitTestDB(\"mysql://user:passwd@mysql-server:4242/\", \"path/to/dumps\", \"my_db\")\n&gt;&gt;&gt; # You can access the database via test_db.dbc, for instance:\n&gt;&gt;&gt; dbc = test_db.dbc\n&gt;&gt;&gt; # At the end do not forget to drop the database\n&gt;&gt;&gt; test_db.drop()\n</code></pre>"},{"location":"reference/ensembl/utils/database/unittestdb/#ensembl.utils.database.unittestdb.TEST_USERNAME","title":"<code>TEST_USERNAME = os.environ.get('USER', 'pytestuser')</code>  <code>module-attribute</code>","text":""},{"location":"reference/ensembl/utils/database/unittestdb/#ensembl.utils.database.unittestdb.UnitTestDB","title":"<code>UnitTestDB</code>","text":"<p>Creates and connects to a new test database, applying the schema and importing the data.</p> <p>Parameters:</p> Name Type Description Default <code>server_url</code> <code>StrURL</code> <p>URL of the server hosting the database.</p> required <code>metadata</code> <code>MetaData | None</code> <p>Use this metadata to create the schema instead of using an SQL schema file.</p> <code>None</code> <code>dump_dir</code> <code>StrPath | None</code> <p>Directory path with the database schema in <code>table.sql</code> (mandatory) and one TSV data file (without headers) per table following the convention <code>&lt;table_name&gt;.txt</code> (optional).</p> <code>None</code> <code>name</code> <code>str | None</code> <p>Name to give to the new database. If not provided, the last directory name of <code>dump_dir</code> will be used instead. In either case, the new database name will be prefixed by the username.</p> <code>None</code> <code>tmp_path</code> <code>StrPath | None</code> <p>Temp dir where the test db is created if using SQLite (otherwise use current dir).</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>dbc</code> <p>Database connection handler.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If <code>table.sql</code> is not found.</p> Source code in <code>src/ensembl/utils/database/unittestdb.py</code> <pre><code>class UnitTestDB:\n    \"\"\"Creates and connects to a new test database, applying the schema and importing the data.\n\n    Args:\n        server_url: URL of the server hosting the database.\n        metadata: Use this metadata to create the schema instead of using an SQL schema file.\n        dump_dir: Directory path with the database schema in `table.sql` (mandatory) and one TSV data\n            file (without headers) per table following the convention `&lt;table_name&gt;.txt` (optional).\n        name: Name to give to the new database. If not provided, the last directory name of `dump_dir`\n            will be used instead. In either case, the new database name will be prefixed by the username.\n        tmp_path: Temp dir where the test db is created if using SQLite (otherwise use current dir).\n\n    Attributes:\n        dbc: Database connection handler.\n\n    Raises:\n        FileNotFoundError: If `table.sql` is not found.\n\n    \"\"\"\n\n    def __init__(\n        self,\n        server_url: StrURL,\n        *,\n        dump_dir: StrPath | None = None,\n        name: str | None = None,\n        metadata: MetaData | None = None,\n        tmp_path: StrPath | None = None,\n    ) -&gt; None:\n        db_url = make_url(server_url)\n        if not name:\n            name = Path(dump_dir).name if dump_dir else \"testdb\"\n        db_name = f\"{TEST_USERNAME}_{name}\"\n\n        # Add the database name to the URL\n        if db_url.get_dialect().name == \"sqlite\":\n            db_path = Path(tmp_path) / db_name if tmp_path else db_name\n            db_url = db_url.set(database=f\"{db_path}.db\")\n        else:\n            db_url = db_url.set(database=db_name)\n        # Enable \"local_infile\" variable for MySQL databases to allow importing data from files\n        connect_args = {}\n        if db_url.get_dialect().name == \"mysql\":\n            connect_args[\"local_infile\"] = 1\n        # Create the database, dropping it beforehand if it already exists\n        if database_exists(db_url):\n            drop_database(db_url)\n        create_database(db_url)\n        # Establish the connection to the database, load the schema and import the data\n        try:\n            self.dbc = DBConnection(db_url, connect_args=connect_args, reflect=False)\n            self._load_schema_and_data(dump_dir, metadata)\n        except:\n            # Make sure the database is deleted before raising the exception\n            drop_database(db_url)\n            raise\n        # Update the loaded metadata information of the database\n        self.dbc.load_metadata()\n\n    def _load_schema_and_data(\n        self, dump_dir: StrPath | None = None, metadata: MetaData | None = None\n    ) -&gt; None:\n        with self.dbc.begin() as conn:\n            # Set InnoDB engine as default and disable foreign key checks for MySQL databases\n            if self.dbc.dialect == \"mysql\":\n                conn.execute(text(\"SET default_storage_engine=InnoDB\"))\n                conn.execute(text(\"SET FOREIGN_KEY_CHECKS=0\"))\n\n            # Load the schema\n            if metadata:\n                metadata.create_all(conn)\n            elif dump_dir:\n                with Path(dump_dir, \"table.sql\").open(\"r\") as schema:\n                    for query in \"\".join(schema.readlines()).split(\";\"):\n                        if query.strip():\n                            conn.execute(text(query))\n\n            # And import any available data for each table\n            if dump_dir:\n                for tsv_file in Path(dump_dir).glob(\"*.txt\"):\n                    table = tsv_file.stem\n                    self._load_data(conn, table, tsv_file)\n\n            # Re-enable foreign key checks for MySQL databases\n            if self.dbc.dialect == \"mysql\":\n                conn.execute(text(\"SET FOREIGN_KEY_CHECKS=1\"))\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Returns a string representation of this object.\"\"\"\n        return f\"{self.__class__.__name__}({self.dbc.url!r})\"\n\n    def drop(self) -&gt; None:\n        \"\"\"Drops the database.\"\"\"\n        drop_database(self.dbc.url)\n        # Ensure the connection pool is properly closed and disposed\n        self.dbc.dispose()\n\n    def _load_data(self, conn: sqlalchemy.engine.Connection, table: str, src: StrPath) -&gt; None:\n        \"\"\"Loads the table data from the given file.\n\n        Args:\n            conn: Open connection to the database.\n            table: Table name to load the data to.\n            src: File path with the data in TSV format (without headers).\n\n        \"\"\"\n        if self.dbc.dialect == \"sqlite\":\n            # SQLite does not have an equivalent to \"LOAD DATA\": use its \".import\" command instead\n            subprocess.run([\"sqlite3\", self.dbc.db_name, \".mode tabs\", f\".import {src} {table}\"], check=True)\n        elif self.dbc.dialect == \"postgresql\":\n            conn.execute(text(f\"COPY {table} FROM '{src}'\"))\n        elif self.dbc.dialect == \"sqlserver\":\n            conn.execute(text(f\"BULK INSERT {table} FROM '{src}'\"))\n        else:\n            conn.execute(text(f\"LOAD DATA LOCAL INFILE '{src}' INTO TABLE {table}\"))\n\n    def __enter__(self) -&gt; UnitTestDB:\n        return self\n\n    def __exit__(self, *args: Any) -&gt; None:\n        self.drop()\n</code></pre>"},{"location":"reference/ensembl/utils/database/unittestdb/#ensembl.utils.database.unittestdb.UnitTestDB.dbc","title":"<code>dbc = DBConnection(db_url, connect_args=connect_args, reflect=False)</code>  <code>instance-attribute</code>","text":""},{"location":"reference/ensembl/utils/database/unittestdb/#ensembl.utils.database.unittestdb.UnitTestDB.drop","title":"<code>drop()</code>","text":"<p>Drops the database.</p> Source code in <code>src/ensembl/utils/database/unittestdb.py</code> <pre><code>def drop(self) -&gt; None:\n    \"\"\"Drops the database.\"\"\"\n    drop_database(self.dbc.url)\n    # Ensure the connection pool is properly closed and disposed\n    self.dbc.dispose()\n</code></pre>"},{"location":"coverage/","title":"Coverage report","text":""}]}